{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAgQTTYNpA9x"
      },
      "source": [
        "# Computer Vision Based EKG Understanding\n",
        "Originally developed for MIT 6.8300 Spring 2023 final project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caPkL5pMqmeO"
      },
      "source": [
        "# Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az1QK-k2Ih_q"
      },
      "outputs": [],
      "source": [
        "####!!!!!!!!!!!!!! NEED TO ADDRESS DATA AUGMENETATION\n",
        "train_the_model = False\n",
        "#model_label = \"STTC_MI_NORM_HYP_CD_fullsize\"\n",
        "#model_label = \"STTC_MI_NORM_HYP_CD_fullsize_1000\"\n",
        "#model_label = \"STTC_MI_NORM_HYP_CD\"\n",
        "model_label = \"NORM_1AVB_WPW_TRIGU_alternate\"\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/image_dir_full_reduced_4/'\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/image_dir_full_reduced_2/'\n",
        "\n",
        "\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/figures_tiny/'\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/figures_99/'\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/figures_test_batch/'\n",
        "\n",
        "\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/image_dir_reduced_2'\n",
        "\n",
        "image_dir = 'drive/MyDrive/68300/MLEKG/image_dir_full_reduced_2_fullsize/'\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/20000/full_1000_2/'\n",
        "\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/Figs_3000/'\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/figures/'\n",
        "\n",
        "labels_csv = 'drive/MyDrive/68300/MLEKG/ptbxl_database.csv'\n",
        "scp_statements_csv = 'drive/MyDrive/68300/MLEKG/scp_statements_mod.csv'\n",
        "\n",
        "image_name_suffix = \"_hr.png\"\n",
        "\n",
        "\n",
        "model_name = 'vgg' \n",
        "batch_size = 2  #16\n",
        "num_epochs = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ8_lvaFg8Kc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = 'drive/MyDrive/68300/MLEKG/trained_models/{}'.format(model_label)\n",
        "#classes_to_include = ['MI','STTC','NORM','CD','HYP']\n",
        "classes_to_include = ['NORM','1AVB','WPW','TRIGU']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gwzuQnz67uX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ast\n",
        "import pandas as pd\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "!pip install tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "import PIL \n",
        "import random\n",
        "from collections import defaultdict\n",
        "from torchvision.transforms.functional import to_grayscale\n",
        "import ast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from math import ceil \n",
        "from matplotlib.ticker import AutoMinorLocator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install grad-cam\n",
        "\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHMQxmK5qzsa"
      },
      "source": [
        "# Specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcysPHDKS8dt"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get a list of all the files in the directory\n",
        "file_list = os.listdir(image_dir)\n",
        "\n",
        "# Calculate the number of elements to remove\n",
        "num_elements_to_remove = int(len(file_list) * 0.9)\n",
        "\n",
        "# Randomly select and remove elements\n",
        "random.shuffle(file_list)\n",
        "removed_elements = file_list[:num_elements_to_remove]\n",
        "file_list = file_list[num_elements_to_remove:]\n",
        "\n",
        "\n",
        "print(len(file_list))\n",
        "# Find the first image in the list\n",
        "image_path = None\n",
        "for filename in file_list:\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        break\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Get the size of the image\n",
        "width, height = image.size\n",
        "image_input_size = (width,height)\n",
        "print(f\"Image size: {width} x {height}\")\n",
        "\n",
        "\n",
        "\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/figures/'\n",
        "\n",
        "\n",
        "\n",
        "print(image_input_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsAOHudzrEx-"
      },
      "source": [
        "# Y Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma1oOSkMGaBp"
      },
      "outputs": [],
      "source": [
        "Y = pd.read_csv(labels_csv, index_col='ecg_id')\n",
        "matches = file_list\n",
        "matches = [int(f.rstrip(image_name_suffix)) for f in matches]\n",
        "#matches = [21817]\n",
        "\n",
        "#Remove all rows from Y unless ecg_id is in matches:\n",
        "Y = Y[Y.index.isin(matches)]\n",
        "\n",
        "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "# Load scp_statements.csv for diagnostic aggregation\n",
        "agg_df = pd.read_csv(scp_statements_csv, index_col=0)\n",
        "agg_df = agg_df[agg_df.diagnostic == 1]\n",
        "\n",
        "def aggregate_diagnostic(y_dic):\n",
        "    tmp = []\n",
        "    for key in y_dic.keys():\n",
        "        if key in agg_df.index:\n",
        "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
        "    return list(set(tmp))\n",
        "\n",
        "# Apply diagnostic superclass\n",
        "Y['diagnostic_individual_list'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
        "\n",
        "#BLINKDLY COMMETING TO TAKE JUST THE FIRST ELEMENT!\n",
        "#Y['diagnostic_superclass'] = Y['diagnostic_superclass'].str[0]\n",
        "\n",
        "#Keep only the first entry of each list in 'diagnostic_superclass': \n",
        "\n",
        "\n",
        "def compare_to_target_list(diagnostic_dict):\n",
        "    #target_list = ['WPW','2AVB']\n",
        "    target_list = [\n",
        "        'NDT', 'NST_', 'DIG', 'LNGQT', 'NORM', 'IMI', 'ASMI', 'LVH', 'LAFB', 'ISC_', 'IRBBB', '1AVB', 'IVCD', 'ISCAL', 'CRBBB',\n",
        "        'CLBBB', 'ILMI', 'LAO/LAE', 'AMI', 'ALMI', 'ISCIN', 'INJAS', 'LMI', 'ISCIL', 'LPFB', 'ISCAS', 'INJAL', 'ISCLA', 'RVH',\n",
        "        'ANEUR', 'RAO/RAE', 'EL', 'WPW', 'ILBBB', 'IPLMI', 'MI', 'STTC', 'HYP', 'ISCAN', 'IPMI', 'SEHYP', 'INJIN', 'INJLA',\n",
        "        'PMI', '3AVB', 'CD', 'INJIL', '2AVB','TRIGU',\n",
        "    ]\n",
        "    return_list = [diag for diag in diagnostic_dict.keys() if diag in target_list]\n",
        "    if len(return_list)<1:\n",
        "      #print(diagnostic_list)\n",
        "      return \"OTHER\"\n",
        "    if 'TRIGU' in return_list:\n",
        "      print(\"RETURNING TRIGU!\")\n",
        "      return 'TRIGU'\n",
        "    return return_list[0]\n",
        "\n",
        "\n",
        "\n",
        "print(Y['diagnostic_individual_list'])\n",
        "# apply function to the dataframe\n",
        "#Y['diagnostic_superclass'] = Y['diagnostic_individual_list'].apply(map_to_class)\n",
        "Y['diagnostic_superclass'] = Y['scp_codes'].apply(compare_to_target_list)\n",
        "\n",
        "print(Y['diagnostic_superclass'])\n",
        "# for index, row in Y.iterrows():\n",
        "#     print(f\"Row {index} --> diagnostic_individual_list: {row['diagnostic_individual_list']}, diagnostic_superclass: {row['diagnostic_superclass']}\")\n",
        "\n",
        "\n",
        "#classes_to_include = ['NORM', 'STTC']\n",
        "# # Filter the rows\n",
        "\n",
        "Y = Y[Y['diagnostic_superclass'].isin(classes_to_include)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Transform 'diagnostic_superclass' labels into numerical labels\n",
        "le = LabelEncoder()\n",
        "Y['diagnostic_superclass_num'] = le.fit_transform(Y['diagnostic_superclass'])\n",
        "\n",
        "\n",
        "# Assume that Y['diagnostic_superclass_num'] contains the numerical labels\n",
        "original_labels = le.inverse_transform(Y['diagnostic_superclass_num'].values)\n",
        "\n",
        "\n",
        "#print(original_labels)\n",
        "test_fold = [10]\n",
        "val_fold = [9]\n",
        "\n",
        "#y_numerical = Y.diagnostic_superclass.factorize()\n",
        "\n",
        "unique_labels, label_counts = np.unique(Y.diagnostic_superclass, return_counts=True)\n",
        "\n",
        "# Print the count of each unique label\n",
        "total_labels = 0\n",
        "for label, count in zip(unique_labels, label_counts):\n",
        "    print(f\"Label {label} appears {count} times\")\n",
        "    total_labels = total_labels + count\n",
        "\n",
        "print(f\"All Labels appears {total_labels} times\")\n",
        "\n",
        "\n",
        "y_val = Y[(Y.strat_fold.isin(val_fold))].diagnostic_superclass_num\n",
        "y_test = Y[Y.strat_fold.isin(test_fold)].diagnostic_superclass_num\n",
        "y_train = Y[(~Y.strat_fold.isin(val_fold)) & (~Y.strat_fold.isin(test_fold))].diagnostic_superclass_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WB5uFRkg8Kd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(1234)\n",
        "  \n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU!\")\n",
        "else:\n",
        "    print(\"WARNING: Could not find GPU! Using CPU only\")\n",
        "    print(\"You may want to try to use the GPU in Google Colab by clicking in:\")\n",
        "    print(\"Runtime > Change Runtime type > Hardware accelerator > GPU.\")\n",
        "    \n",
        "    \n",
        "def initialize_model(model_name, num_classes, resume_from = None, use_pretrained = False):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    # The model (nn.Module) to return\n",
        "    model_ft = None\n",
        "    # The input image is expected to be (input_size, input_size)\n",
        "    #input_size = 0\n",
        "    \n",
        "    # By default, all parameters will be trained (useful when you're starting from scratch)\n",
        "    # Within this function you can set .requires_grad = False for various parameters, if you\n",
        "    # don't want to learn them\n",
        "\n",
        "\n",
        "\n",
        "    if model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = image_input_size\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Invalid model name!\")\n",
        "    \n",
        "    if resume_from is not None:\n",
        "        print(\"Loading weights from %s\" % resume_from)\n",
        "        model_ft.load_state_dict(torch.load(resume_from))\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "def make_optimizer(model, learning_rate, print_parameters=False):\n",
        "    # Get all the parameters\n",
        "    params_to_update = model.parameters()\n",
        "    if print_parameters:\n",
        "      print(\"Params to learn:\")\n",
        "      for name, param in model.named_parameters():\n",
        "          if param.requires_grad == True:\n",
        "              print(\"\\t\",name)\n",
        "\n",
        " \n",
        "    #optimizer = optim.SGD(params_to_update, lr=learning_rate, momentum=0.9)\n",
        "    optimizer = optim.Adam(params_to_update, lr=learning_rate)\n",
        "    #optimizer = optim.Adagrad(params_to_update, lr=learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "def get_loss():\n",
        "    # Create an instance of the loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    return criterion\n",
        "\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, save_dir = None, save_all_epochs=False, num_epochs=25):\n",
        "    '''\n",
        "    model: The NN to train\n",
        "    dataloaders: A dictionary containing at least the keys \n",
        "                 'train','val' that maps to Pytorch data loaders for the dataset\n",
        "    criterion: The Loss function\n",
        "    optimizer: The algorithm to update weights \n",
        "               (Variations on gradient descent)\n",
        "    num_epochs: How many epochs to train for\n",
        "    save_dir: Where to save the best model weights that are found, \n",
        "              as they are found. Will save to save_dir/weights_best.pt\n",
        "              Using None will not write anything to disk\n",
        "    save_all_epochs: Whether to save weights for ALL epochs, not just the best\n",
        "                     validation error epoch. Will save to save_dir/weights_e{#}.pt\n",
        "    '''\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    train_acc_history = []\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                print(\"switching model to train\")\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            # TQDM has nice progress bars\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # torch.max outputs the maximum value, and its index\n",
        "                    # Since the input is batched, we take the max along axis 1\n",
        "                    # (the meaningful outputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backprop + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            \n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "            if save_all_epochs:\n",
        "                torch.save(model.state_dict(), os.path.join(save_dir, f'weights_{epoch}.pt'))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # save and load best model weights\n",
        "    torch.save(best_model_wts, os.path.join(save_dir, 'weights_best_val_acc.pt'))\n",
        "    torch.save(model.state_dict(), os.path.join(save_dir, 'weights_last.pt'.format(epoch)))\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, train_acc_history\n",
        "\n",
        "def get_image_transforms():\n",
        "    # How to transform the image when you are loading them.\n",
        "    # you'll likely want to mess with the transforms on the training set.\n",
        "    \n",
        "    # We convert the image to a [C,H,W] tensor, then normalize it to values with a given mean/stdev. These normalization constants\n",
        "    # are derived from the mean/stdev of the ImageNet training set which was used to pretrain our models.\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    return transform\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, image_ids, labels, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.image_ids = image_ids\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.data_dir, f\"{str(self.image_ids[idx]).zfill(5)}{image_name_suffix}\")\n",
        "        image = Image.open(img_name)\n",
        "        \n",
        "        # Check if the image has a corresponding label\n",
        "        if self.labels is not None:\n",
        "            label = self.labels[idx]\n",
        "        else:\n",
        "            label = None\n",
        "        \n",
        "        # Apply data augmentation if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def make_balanced_sampler(labels):\n",
        "    class_counts = np.bincount(labels)\n",
        "    class_weights = 1. / class_counts\n",
        "    samples_weights = class_weights[labels]\n",
        "    sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)\n",
        "    return sampler\n",
        "\n",
        "\n",
        "def get_dataloaders(dataset_dir, input_size, batch_size, shuffle=True, transform=get_image_transforms()):\n",
        "    data_transforms = {\n",
        "        'train': transform,\n",
        "        'val': transform,\n",
        "        'test': transform\n",
        "    }\n",
        "\n",
        "    # Get the list of image IDs with labels\n",
        "    train_image_ids = y_train.index[y_train.notnull()]\n",
        "    val_image_ids = y_val.index[y_val.notnull()]\n",
        "    test_image_ids = y_test.index[y_test.notnull()]\n",
        "\n",
        "    # Get the labels for the images with labels\n",
        "    train_labels = y_train.loc[train_image_ids].to_numpy()\n",
        "    val_labels = y_val.loc[val_image_ids].to_numpy()\n",
        "    test_labels = y_test.loc[test_image_ids].to_numpy()\n",
        "    \n",
        "    # Make a balanced sampler for the training set\n",
        "    train_sampler = make_balanced_sampler(train_labels)\n",
        "\n",
        "    # Create the datasets\n",
        "    train_dataset = CustomDataset(dataset_dir, train_image_ids, train_labels, transform=data_transforms['train'])\n",
        "    val_dataset = CustomDataset(dataset_dir, val_image_ids, val_labels, transform=data_transforms['val'])\n",
        "    test_dataset = CustomDataset(dataset_dir, test_image_ids, test_labels, transform=data_transforms['test'])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
        "\n",
        "    dataloaders_dict = {\n",
        "        'train': train_dataloader,\n",
        "        'val': val_dataloader,\n",
        "        'test': test_dataloader\n",
        "    }\n",
        "    return dataloaders_dict\n",
        "\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
        "# You can add your own, or modify these however you wish!\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = Y['diagnostic_superclass'].nunique()\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "\n",
        "# Shuffle the input data?\n",
        "shuffle_datasets = True\n",
        "\n",
        "# Number of epochs to train for \n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "### IO\n",
        "# Path to a model file to use to start weights at\n",
        "resume_from = None\n",
        "\n",
        "# Whether to use a pretrained model, trained for classification in Imagenet-1k \n",
        "pretrained = False\n",
        "\n",
        "# Save all epochs so that you can select the model from a particular epoch\n",
        "save_all_epochs = False\n",
        "\n",
        "# Whether to use early stopping (load the model with best accuracy), or not\n",
        "early_stopping = True\n",
        "\n",
        "# Directory to save weights to\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Initialize the model for this run\n",
        "# train model_1\n",
        "model_1, input_size = initialize_model(model_name = model_name, num_classes = num_classes, resume_from=resume_from, use_pretrained=pretrained)\n",
        "dataloaders = get_dataloaders(image_dir, input_size, batch_size, shuffle_datasets)\n",
        "criterion = get_loss()\n",
        "\n",
        "\n",
        "train_dataloader = dataloaders['train']\n",
        "\n",
        "num_batches_to_print = 3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSyS30OWrbkL"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqbHvzZPWsk6"
      },
      "outputs": [],
      "source": [
        "print(unique_labels, label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PewM9KjF6W3O"
      },
      "outputs": [],
      "source": [
        "if train_the_model:\n",
        "  # Move the model to the gpu if needed\n",
        "  model_1 = model_1.to(device)\n",
        "\n",
        "  optimizer_1 = make_optimizer(model_1, learning_rate)\n",
        "\n",
        "  # Train the model!\n",
        "  trained_model_1, validation_history_1, train_history_1 = train_model(model=model_1, \n",
        "                                                                      dataloaders=dataloaders, \n",
        "                                                                      criterion=criterion, \n",
        "                                                                      optimizer=optimizer_1,\n",
        "                                                                      save_dir=save_dir, \n",
        "                                                                      save_all_epochs=save_all_epochs, \n",
        "                                                                      num_epochs=num_epochs)\n",
        "  del model_1, optimizer_1, trained_model_1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOj4EJMRreej"
      },
      "source": [
        "# Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBt3EbutF7YR"
      },
      "outputs": [],
      "source": [
        "# Load your final model, that we will use for the rest of the PSET.\n",
        "if early_stopping:\n",
        "  weights_file = save_dir + '/weights_best_val_acc.pt'\n",
        "else:\n",
        "  weights_file = save_dir + '/weights_last.pt'\n",
        "model_yours, _ = initialize_model(model_name = model_name, num_classes = num_classes, resume_from=resume_from, use_pretrained=pretrained)\n",
        "\n",
        "# Move the model to the gpu if needed\n",
        "model_yours = model_yours.to(device)\n",
        "\n",
        "# Load weights for model_yours\n",
        "#model_yours.load_state_dict(torch.load(weights_file))\n",
        "model_yours.load_state_dict(torch.load(weights_file,map_location=torch.device('cpu')))\n",
        "\n",
        "\n",
        "# set models to eval mode\n",
        "model_yours = model_yours.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJygIBqNri35"
      },
      "source": [
        "# Confusion Mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlkyj8qhg8Kn"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, is_labelled = False, generate_labels = True, k = 5):\n",
        "    # If is_labelled, we want to compute loss, top-1 accuracy and top-5 accuracy\n",
        "    # If generate_labels, we want to output the actual labels\n",
        "    # Set the model to evaluate mode\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    running_top1_correct = 0\n",
        "    running_top5_correct = 0\n",
        "    predicted_labels = []\n",
        "    gt_labels = []\n",
        "\n",
        "    # Iterate over data.\n",
        "    # TQDM has nice progress bars\n",
        "    for inputs, labels in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        tiled_labels = torch.stack([labels.data for i in range(k)], dim=1) \n",
        "        # Makes this to calculate \"top 5 prediction is correct\"\n",
        "        # [[label1 label1 label1 label1 label1], [label2 label2 label2 label label2]]\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(False):\n",
        "            # Get model outputs and calculate loss\n",
        "            outputs = model(inputs)\n",
        "            if is_labelled:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # torch.topk outputs the maximum values, and their indices\n",
        "            # Since the input is batched, we take the max along axis 1\n",
        "            # (the meaningful outputs)\n",
        "            _, preds = torch.topk(outputs, k=k, dim=1)\n",
        "            if generate_labels:\n",
        "                # We want to store these results\n",
        "                nparr = preds.cpu().detach().numpy()\n",
        "                predicted_labels.extend([list(nparr[i]) for i in range(len(nparr))])\n",
        "                gt_labels.extend(np.array(labels.cpu()))\n",
        "\n",
        "        if is_labelled:\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            # Check only the first prediction\n",
        "            running_top1_correct += torch.sum(preds[:, 0] == labels.data)\n",
        "            # Check all 5 predictions\n",
        "            running_top5_correct += torch.sum(preds == tiled_labels)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    # Only compute loss & accuracy if we have the labels\n",
        "    if is_labelled:\n",
        "        epoch_loss = float(running_loss / len(dataloader.dataset))\n",
        "        epoch_top1_acc = float(running_top1_correct.double() / len(dataloader.dataset))\n",
        "        epoch_top5_acc = float(running_top5_correct.double() / len(dataloader.dataset))\n",
        "    else:\n",
        "        epoch_loss = None\n",
        "        epoch_top1_acc = None\n",
        "        epoch_top5_acc = None\n",
        "    \n",
        "    # Return everything\n",
        "    return epoch_loss, epoch_top1_acc, gt_labels, predicted_labels  \n",
        "\n",
        "# Wrapper to easily evaulate a model given a model and the set of dataloaders\n",
        "def get_eval_results(model, dataloaders):\n",
        "    model.eval()\n",
        "    true_label_list = []\n",
        "    outputs_list = []\n",
        "    predicted_label_list = []\n",
        "    original_image_list = []\n",
        "\n",
        "    # TQDM has nice progress bars\n",
        "    for inputs, labels in tqdm(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        with torch.set_grad_enabled(False):\n",
        "            # Get model outputs and calculate loss\n",
        "            outputs = model(inputs)\n",
        "            true_label_list.append(labels)\n",
        "            original_image_list.append(inputs)\n",
        "            outputs_list.append(outputs)\n",
        "            _, preds = torch.topk(outputs, k=1, dim=1)\n",
        "            predicted_label_list.append(preds)\n",
        "    return torch.concat(true_label_list).unsqueeze(-1).cpu().numpy(), \\\n",
        "           torch.concat(predicted_label_list).cpu().numpy(), \\\n",
        "           torch.softmax(torch.concat(outputs_list), dim=1).cpu().numpy(), \\\n",
        "           torch.concat(original_image_list).cpu().numpy()\n",
        "\n",
        "\n",
        "# Get data on the validation set\n",
        "# Setting this to false will be a little bit faster\n",
        "generate_validation_labels = True\n",
        "\n",
        "model = model_yours\n",
        "\n",
        "## Please make sure you understand what outputs means here\n",
        "y_label, y_pred, outputs, inputs =  get_eval_results(model, dataloaders)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_label)\n",
        "print(label_map)"
      ],
      "metadata": {
        "id": "aOmvlRH1i4oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_label, y_pred, title='Confusion matrix'):\n",
        "    # Calculate the confusion matrix\n",
        "    num_classes = len(np.unique(y_label))\n",
        "    print(num_classes)\n",
        "    confusion_matrix = np.zeros([num_classes,num_classes])\n",
        "    for i in range(len(y_label)):\n",
        "        confusion_matrix[y_label[i], y_pred[i]] += 1\n",
        "\n",
        "    # Save raw numbers for display\n",
        "    confusion_matrix_raw = confusion_matrix \n",
        "\n",
        "    # Convert to percentage\n",
        "    confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plot the confusion matrix as a heatmap with sorted vertical axis\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Annoying loops for labeling\n",
        "    for i in np.arange(0,num_classes):\n",
        "        for j in np.arange(0,num_classes):\n",
        "            #ax.text(j + 0.5, i + 0.5, '{:.1%}'.format(confusion_matrix[i, j]),\n",
        "            #       ha='center', va='center', color='black')\n",
        "            ax.text(j + 0.5, i + 0.5, '{:.1%}\\n{:.0f}'.format(confusion_matrix[i, j], confusion_matrix_raw[i, j]),\n",
        "                    ha='center', va='center', color='black')\n",
        "\n",
        "\n",
        "    sns.heatmap(confusion_matrix, cmap='Blues', annot=False)\n",
        "   \n",
        "    ax.set_xticklabels(classes, rotation=90)  # Set text labels on x axis\n",
        "    ax.set_yticklabels(classes, rotation=0)   # Set text labels on y axis\n",
        "\n",
        "    ax.set_xlabel('Predicted')  # Set x-axis label\n",
        "    ax.set_ylabel('Truth')  # Set y-axis label\n",
        "\n",
        "    ax.set_title(title)\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "    return confusion_matrix\n",
        "    \n",
        "classes = le.classes_\n",
        "\n",
        "label_map = {i: label for i, label in enumerate(classes)}\n",
        "\n",
        "confusion_matrix = plot_confusion_matrix(y_label, y_pred)\n",
        "print(confusion_matrix)"
      ],
      "metadata": {
        "id": "Bn9ZdWUCi4zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w0V7JIV9lip"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_label, y_pred, title='Confusion matrix'):\n",
        "    # Calculate the confusion matrix\n",
        "    num_classes = len(np.unique(y_label))\n",
        "    print(num_classes)\n",
        "    confusion_matrix = np.zeros([num_classes,num_classes])\n",
        "    for i in range(len(y_label)):\n",
        "        confusion_matrix[y_label[i], y_pred[i]] += 1\n",
        "\n",
        "    # Save raw numbers for display\n",
        "    confusion_matrix_raw = confusion_matrix \n",
        "\n",
        "    # Convert to percentage\n",
        "    confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plot the confusion matrix as a heatmap with sorted vertical axis\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Annoying loops for labeling\n",
        "    for i in np.arange(0,num_classes):\n",
        "        for j in np.arange(0,num_classes):\n",
        "            #ax.text(j + 0.5, i + 0.5, '{:.1%}'.format(confusion_matrix[i, j]),\n",
        "            #       ha='center', va='center', color='black')\n",
        "            ax.text(j + 0.5, i + 0.5, '{:.1%}\\n{:.0f}'.format(confusion_matrix[i, j], confusion_matrix_raw[i, j]),\n",
        "                    ha='center', va='center', color='black')\n",
        "\n",
        "\n",
        "    sns.heatmap(confusion_matrix, cmap='Blues', annot=False)\n",
        "   \n",
        "    ax.set_xticklabels(classes, rotation=90)  # Set text labels on x axis\n",
        "    ax.set_yticklabels(classes, rotation=0)   # Set text labels on y axis\n",
        "\n",
        "    ax.set_xlabel('Predicted')  # Set x-axis label\n",
        "    ax.set_ylabel('Truth')  # Set y-axis label\n",
        "\n",
        "    ax.set_title(title)\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "    return confusion_matrix\n",
        "    \n",
        "classes = le.classes_\n",
        "\n",
        "label_map = {i: label for i, label in enumerate(classes)}\n",
        "\n",
        "confusion_matrix = plot_confusion_matrix(y_label, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx-PjTCxg8Ko"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_sensitivity_specificity(confusion_matrix):\n",
        "    # Ensure the confusion matrix is a numpy array\n",
        "    confusion_matrix = np.array(confusion_matrix)\n",
        "\n",
        "    # Calculate the total sum of the confusion matrix\n",
        "    total = np.sum(confusion_matrix)\n",
        "    \n",
        "    if confusion_matrix.shape[0] != confusion_matrix.shape[1]:\n",
        "        return \"The provided confusion matrix is not square\"\n",
        "    \n",
        "    sensitivity = []\n",
        "    specificity = []\n",
        "    \n",
        "    for i in range(confusion_matrix.shape[0]):\n",
        "        # Sensitivity (also known as true positive rate or recall)\n",
        "        tp = confusion_matrix[i,i]\n",
        "        fn = np.sum(confusion_matrix[i,:]) - tp\n",
        "        sensitivity.append(tp / (tp + fn))\n",
        "\n",
        "        # Specificity (also known as true negative rate)\n",
        "        tn = total - np.sum(confusion_matrix[i,:]) - np.sum(confusion_matrix[:,i]) + tp\n",
        "        fp = np.sum(confusion_matrix[:,i]) - tp\n",
        "        specificity.append(tn / (tn + fp))\n",
        "\n",
        "    return sensitivity, specificity\n",
        "\n",
        "sensitivity, specificity = calculate_sensitivity_specificity(confusion_matrix)\n",
        "print(label_map)\n",
        "print(\"Sensitivity: \", sensitivity)\n",
        "print(\"Specificity: \", specificity)\n",
        "\n",
        "# Assuming the label_map, sensitivity, and specificity are defined\n",
        "for i in range(len(label_map)):\n",
        "    print(f\"{label_map[i]} - Sensitivity: {sensitivity[i]:.4f}, Specificity: {specificity[i]:.4f}\")\n",
        "\n",
        "\n",
        "# {0: 'CD', 1: 'HYP', 2: 'MI', 3: 'NORM', 4: 'STTC'}\n",
        "# Sensitivity:  [0.06451612903225806, 0.0, 0.47368421052631576, 0.9770114942528736, 0.7647058823529411]\n",
        "# Specificity:  [1.0, 1.0, 0.8899430740037951, 0.5959419421418823, 0.8340944128954199]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCt6Oqy9FxNo"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.feature = None\n",
        "        self.gradient = None\n",
        "\n",
        "    def save_gradient(self, grad):\n",
        "        self.gradient = grad\n",
        "\n",
        "    def __call__(self, x):\n",
        "        image_size = (x.size(-1), x.size(-2))\n",
        "        feature_maps = []\n",
        "\n",
        "        for i in range(x.size(0)):\n",
        "            img = x[i].data.cpu().numpy()\n",
        "            img = img - np.min(img)\n",
        "            if np.max(img) != 0:\n",
        "                img = img / np.max(img)\n",
        "\n",
        "            feature = x[i].unsqueeze(0)\n",
        "\n",
        "            for name, module in self.model.named_children():\n",
        "                if name == 'classifier':\n",
        "                    feature = feature.view(feature.size(0), -1)\n",
        "                feature = module(feature)\n",
        "                if name == 'features':\n",
        "                    feature.register_hook(self.save_gradient)\n",
        "                    self.feature = feature\n",
        "            classes = F.sigmoid(feature)\n",
        "            one_hot, _ = classes.max(dim=-1)\n",
        "            self.model.zero_grad()\n",
        "            one_hot.backward()\n",
        "            weight = self.gradient.mean(dim=-1, keepdim=True).mean(dim=-2, keepdim=True)\n",
        "            mask = F.relu((weight * self.feature).sum(dim=1)).squeeze(0)\n",
        "            mask = cv2.resize(mask.data.cpu().numpy(), image_size)\n",
        "            mask = mask - np.min(mask)\n",
        "\n",
        "            if np.max(mask) != 0:\n",
        "                mask = mask / np.max(mask)\n",
        "\n",
        "            feature_map = np.float32(cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET))\n",
        "            cam = feature_map + np.float32((np.uint8(img.transpose((1, 2, 0)) * 255)))\n",
        "            cam = cam - np.min(cam)\n",
        "\n",
        "            if np.max(cam) != 0:\n",
        "                cam = cam / np.max(cam)\n",
        "\n",
        "            feature_maps.append(transforms.ToTensor()(cv2.cvtColor(np.uint8(255 * cam), cv2.COLOR_BGR2RGB)))\n",
        "\n",
        "        feature_maps = torch.stack(feature_maps)\n",
        "\n",
        "        return feature_maps\n",
        "\n",
        "# def visualize(img, cam):\n",
        "#     plt.figure(figsize=(10,10))\n",
        "#     plt.subplot(1,2,1)\n",
        "#     plt.imshow(np.transpose(img,(1,2,0)))\n",
        "#     plt.title('Input Image')\n",
        "#     plt.subplot(1,2,2)\n",
        "#     plt.imshow(np.transpose(cam,(1,2,0)))\n",
        "#     plt.title('Grad-CAM')\n",
        "#     plt.show()\n",
        "\n",
        "# def visualize(img, cam, label):\n",
        "#     plt.figure(figsize=(10,10))\n",
        "#     plt.subplot(1,2,1)\n",
        "#     plt.imshow(np.transpose(img,(1,2,0)))\n",
        "#     if label == 0:\n",
        "#       label = \"SBRAD\"\n",
        "#     elif label == 1:\n",
        "#       label = \"AFIB\"\n",
        "#     plt.title('Input Image - Label: {}'.format(label))\n",
        "#     plt.subplot(1,2,2)\n",
        "#     plt.imshow(np.transpose(cam,(1,2,0)))\n",
        "#     plt.title('Grad-CAM - Label: {}'.format(label))\n",
        "#     plt.show()\n",
        "\n",
        "def visualize(img, cam, ground_truth, prediction):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(np.transpose(img,(1,2,0)))\n",
        "    plt.title('Input Image - Ground Truth: {}'.format(ground_truth))\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(np.transpose(cam,(1,2,0)))\n",
        "    plt.title('Grad-CAM - Predicted: {}'.format(prediction))\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUTBf9GNv_E9"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "original_labels = le.inverse_transform(Y['diagnostic_superclass_num'].values)\n",
        "label_map = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Assume that dataloaders['test'] and model are already defined\n",
        "grad_cam = GradCAM(model)\n",
        "\n",
        "# Loop over all batches in the 'test' set\n",
        "for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    # Make a prediction for each input\n",
        "    outputs = model(inputs)\n",
        "    #test_loss_yours, test_top1_yours, _, test_labels_yours\n",
        "    #outputs = test_labels_yours\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    # Apply GradCAM\n",
        "    cams = grad_cam(inputs)\n",
        "\n",
        "    # Visualize the original images and Grad-CAM heatmaps\n",
        "    for j in range(inputs.size(0)):\n",
        "        ground_truth = label_map[labels[j].item()]\n",
        "        prediction = label_map[preds[j].item()]\n",
        "        visualize(inputs[j].cpu(), cams[j].cpu(), ground_truth, prediction)\n",
        "\n",
        "    # You may want to break the loop after a few batches to avoid producing too many images\n",
        "    if i == 10:  # Just print for 5 batches\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJigpgYH-ZtG"
      },
      "source": [
        "# Grad CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E7_FmPOwmGD"
      },
      "outputs": [],
      "source": [
        "def grad_cam(input_model, image, class_idx, feature_module):\n",
        "    model_features = list(input_model.children())[:-1]\n",
        "\n",
        "    model = torch.nn.Sequential(*model_features)\n",
        "\n",
        "    feature = model(image)\n",
        "    feature = feature.detach().cpu().numpy()\n",
        "\n",
        "    weight_softmax_params = list(input_model.parameters())[-2]\n",
        "    weight_softmax = np.squeeze(weight_softmax_params.detach().cpu().numpy())\n",
        "\n",
        "    class_weights = weight_softmax[class_idx]\n",
        "    cam = feature.dot(class_weights)\n",
        "\n",
        "    # Process CAM\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cam / cam.max()\n",
        "    return cam\n",
        "\n",
        "def plot_grad_cam(cam, img):\n",
        "    img = np.transpose(img, (1,2,0))\n",
        "    img = (img - np.min(img)) / np.ptp(img)\n",
        "    cam_heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "    cam_heatmap = cv2.cvtColor(cam_heatmap, cv2.COLOR_BGR2RGB)\n",
        "    cam = np.float32(cam_heatmap) + np.float32(img)\n",
        "    cam = 255 * cam / np.max(cam)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(np.uint8(cam))\n",
        "    plt.show()\n",
        "\n",
        "y_label, y_pred, outputs, inputs = get_eval_results(model, dataloaders)\n",
        "\n",
        "# Visualize Grad-CAM for correctly and incorrectly predicted images\n",
        "for i in range(len(y_label)):\n",
        "    img = inputs[i]\n",
        "    true_label = y_label[i]\n",
        "    pred_label = y_pred[i]\n",
        "\n",
        "    cam = grad_cam(model, img, pred_label, model.layer4)\n",
        "    plot_grad_cam(cam, img)\n",
        "\n",
        "    if i > 10: # Limit to 10 images for brevity\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWE-y9TiYICo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a dictionary that maps the integer label to the alphabetical label\n",
        "\n",
        "print(label_map)\n",
        "# Print the mapping\n",
        "for integer, label in label_map.items():\n",
        "    print(f\"{integer} --> {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTiBYmq9C-qu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def precision_recall_curve(probabilities, y_label, y_pred):\n",
        "    end = len(y_label)\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    decision_thresholds = np.arange(0,1,0.001)\n",
        "    \n",
        "    new_y_label = []\n",
        "    for i in range(0,end):\n",
        "      if y_label[i] == 1:\n",
        "        new_y_label.append(1)\n",
        "      else:\n",
        "        new_y_label.append(0)\n",
        "        \n",
        "\n",
        "    for decision_threshold in decision_thresholds:\n",
        "      new_y_pred = []\n",
        "\n",
        "  \n",
        "      for i in range(0,end):\n",
        "        probs = probabilities[i]\n",
        "        ground_truth = y_label[i]\n",
        "        if probs[1] > decision_threshold:\n",
        "          new_y_pred.append(1)\n",
        "        else:\n",
        "          new_y_pred.append(0)\n",
        "\n",
        "      # Calculate true/false positive/negative\n",
        "      tp,fp,tn,fn = 0,0,0,0\n",
        "      for i in range(len(new_y_label)):\n",
        "            if new_y_label[i] == 1 and new_y_pred[i] == 1:\n",
        "                tp += 1\n",
        "            elif new_y_label[i] == 0 and new_y_pred[i] == 1:\n",
        "                fp += 1\n",
        "            elif new_y_label[i] == 0 and new_y_pred[i] == 0:\n",
        "                tn += 1\n",
        "            elif new_y_label[i] == 1 and new_y_pred[i] == 0:\n",
        "                fn += 1\n",
        "\n",
        "      # Handle edge cases (not sure if there is a different convention needed)\n",
        "      if (tp+fn)==0:\n",
        "        recall = 1\n",
        "      else:\n",
        "        recall = tp/(tp+fn)\n",
        "\n",
        "      if (tp+fp)==0:\n",
        "        precision= 1\n",
        "      else:\n",
        "        precision = tp/(tp+fp)\n",
        "\n",
        "      precisions.append(precision)\n",
        "      recalls.append(recall)\n",
        "\n",
        "    # Finally, calulate AUC\n",
        "    auc = np.trapz(recalls,precisions)\n",
        "    annotation=\"AUC: {:.5}\".format(auc)\n",
        "\n",
        "    #Reference for color line: https://matplotlib.org/stable/gallery/lines_bars_and_markers/multicolored_line.html\n",
        "    # I couldn't get a color line to work (not neede for the homework, is just cool)\n",
        "    # But Im leaving this in to hopefully come back to it later.\n",
        "\n",
        "    # Plot it\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.plot(recalls, precisions)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.xlim(0,1.1)\n",
        "    plt.ylim(0,0.7)\n",
        "    plt.text(0.1,0.1,annotation, fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "    return(precisions,recalls)\n",
        "\n",
        "precisions,recalls = precision_recall_curve(outputs, y_label, y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buxAeJL-DmAr"
      },
      "outputs": [],
      "source": [
        "def plot_cams(target_dataloaders, cam_method=GradCAM, class_id='gt'):\n",
        "  #assert class_id in ['gt', 'pred'] or type(class_id) is int and class_id < 3\n",
        "  for split in ['train', 'val', 'test']:\n",
        "    #target_layers = [model.layer4[-1]]\n",
        "    target_layer=model.features[-1]\n",
        "    fig, axs = plt.subplots(2, 6, figsize=(14, 7))\n",
        "    fig.suptitle(\"Examples split {}, class {}\".format(split, class_id), fontsize=16)\n",
        "\n",
        "    split_dataset = target_dataloaders[split].dataset\n",
        "    indices_per_class = defaultdict(list)\n",
        "    for i, (_, c) in enumerate(split_dataset.imgs):\n",
        "      indices_per_class[c].append(i)\n",
        "\n",
        "    random.seed(1337)  \n",
        "    indices = []\n",
        "    for c in range(3):\n",
        "      indices.extend(random.sample(indices_per_class[c], 4))\n",
        "\n",
        "    for dataset_i, ax in zip(indices, axs.flatten()):\n",
        "      input_tensor, class_idx = split_dataset[dataset_i]\n",
        "      input_tensor = input_tensor[None,...].cuda()\n",
        "\n",
        "      # Construct the CAM object once, and then re-use it on many images:\n",
        "      cam = cam_method(model=model, target_layers=target_layers, use_cuda=not device == 'cpu')\n",
        "      pred_class_idx = model(input_tensor).argmax()\n",
        "\n",
        "      # We have to specify the target we want to generate\n",
        "      # the Class Activation Maps for\n",
        "      if type(class_id) is int:\n",
        "        target_class_id = class_id\n",
        "      else:\n",
        "        target_class_id = pred_class_idx if class_id == 'pred' else class_idx        \n",
        "      targets = [ClassifierOutputTarget(target_class_id)]\n",
        "\n",
        "      # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
        "      grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "      # In this example grayscale_cam has only one image in the batch:\n",
        "      grayscale_cam = grayscale_cam[0, :]\n",
        "      rgb_image = np.array(input_tensor[0].cpu())\n",
        "      rgb_image = (rgb_image - rgb_image.min())/ (rgb_image.max() - rgb_image.min())\n",
        "      visualization = show_cam_on_image(rgb_image.transpose((1,2,0)), grayscale_cam, use_rgb=True)\n",
        "      \n",
        "      ax.set_title('True : %s\\n Predicted: %s' %(split_dataset.classes[class_idx], split_dataset.classes[pred_class_idx]))\n",
        "      ax.imshow(visualization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4KSEF-QPrHG"
      },
      "outputs": [],
      "source": [
        "# Substitute GradCAM for one of the following, to test other methods:\n",
        "# GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "# Also substitute class_id for pred, or a class id in [0,1,2] to check different output.\n",
        "#plot_cams(dataloaders, cam_method=GradCAM, class_id='gt')\n",
        "#plot_cams(dataloaders, cam_method=GradCAM, class_id='pred')\n",
        "#plot_cams(dataloaders, cam_method=GradCAM, class_id=1)\n",
        "plot_cams(dataloaders, cam_method=GradCAM, class_id=3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8JRZyR9mQIv"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "class RebalancedDataset(datasets.ImageFolder):\n",
        "  def __init__(self, class_probabilities, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.class_probabilities = class_probabilities\n",
        "    self.items_per_class = defaultdict(list)\n",
        "    \n",
        "    for item_i, (_, c) in enumerate(self.imgs):\n",
        "      self.items_per_class[c].append(item_i)\n",
        "\n",
        "  def __getitem__(self, i_ignored):\n",
        "    # ignores argument, and returns an element at random with reweighted class\n",
        "    if i_ignored >= len(self):\n",
        "      raise IndexError('Index is too large') # Exception required so that the iterator ends after len(self) samples\n",
        "\n",
        "    # TODO: select a class at random following self.class_probabilities, and then select a random element for the class\n",
        "    class_i = random.choices(range(len(self.classes)), weights=self.class_probabilities)[0]\n",
        "    i = random.choice(self.items_per_class[class_i])\n",
        "    # ENDTODO\n",
        "    return super().__getitem__(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bTmJQinfn8-"
      },
      "outputs": [],
      "source": [
        "# Replicates the original get_dataloaders, but in this case we substitute the training dataset for the RebalancedDataset\n",
        "def get_dataloaders_rebalanced(class_probabilities, dataset_dir, input_size, batch_size, shuffle = True):\n",
        "    data_transforms = {\n",
        "        'train': get_image_transforms(),\n",
        "        'val': get_image_transforms(),\n",
        "        'test': get_image_transforms()\n",
        "    }\n",
        "\n",
        "    # Create training and validation datasets\n",
        "    image_datasets = {'train': RebalancedDataset(class_probabilities, os.path.join(dataset_dir, 'train'), data_transforms['train']),\n",
        "                      'val': datasets.ImageFolder(os.path.join(dataset_dir, 'val'), data_transforms['val']),\n",
        "                      'test': datasets.ImageFolder(os.path.join(dataset_dir, 'test'), data_transforms['test'])}\n",
        "    # Create training and validation dataloaders\n",
        "    # Never shuffle the test set\n",
        "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False if x != 'train' else shuffle, num_workers=4) for x in data_transforms.keys()}\n",
        "    return dataloaders_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db-nFvcZiFtC"
      },
      "outputs": [],
      "source": [
        "class_probabilities = [1/3 for _ in range(3)]\n",
        "dataloaders_rebalanced = get_dataloaders_rebalanced(class_probabilities, mias_dataset_dir, input_size, batch_size, shuffle_datasets)\n",
        "\n",
        "train_dataset_rebalanced = dataloaders_rebalanced['train'].dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r54M9pTqi5nr"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict \n",
        "\n",
        "samples_per_class_rebalanced = [0 for _ in range(3)]\n",
        "for _, class_idx in tqdm(train_dataset_rebalanced):\n",
        "  samples_per_class_rebalanced[class_idx] += 1\n",
        "\n",
        "print(\"Rebalanced samples per class:\")\n",
        "for c_idx in range(3):\n",
        "  print(\"Class {} ({}): {} samples\".format(c_idx, train_dataset_rebalanced.classes[c_idx], samples_per_class_rebalanced[c_idx]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn6jor9biDer"
      },
      "outputs": [],
      "source": [
        "model_rebalanced, input_size = initialize_model(model_name = model_name, num_classes = num_classes, resume_from=resume_from, use_pretrained=pretrained)\n",
        "\n",
        "model_rebalanced = model_rebalanced.to(device)\n",
        "optimizer_rebalanced = make_optimizer(model_rebalanced, learning_rate)\n",
        "trained_rebalanced, validation_history_rebalanced, train_history_rebalanced = train_model(model=model_rebalanced, \n",
        "                                                                                          dataloaders=dataloaders_rebalanced, \n",
        "                                                                                          criterion=criterion, \n",
        "                                                                                          optimizer=optimizer_rebalanced,\n",
        "                                                                                          save_dir=save_dir, \n",
        "                                                                                          save_all_epochs=save_all_epochs, \n",
        "                                                                                          num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcDKG0EaFNiA"
      },
      "outputs": [],
      "source": [
        "y_label_rebalanced, y_pred_rebalanced, _, _ =  get_eval_results(model_rebalanced, dataloaders)\n",
        "plot_confusion_matrix(y_label_rebalanced, y_pred_rebalanced, title='CM rebalanced')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "save_dir = 'drive/MyDrive/68300/MLEKG/trained_models/{}'.format(model_label)\n",
        "classes_to_include = ['NORM','1AVB','WPW','TRIGU']\n",
        "\n",
        "\n",
        "# Get a list of all the files in the directory\n",
        "file_list = os.listdir(image_dir)\n",
        "\n",
        "print(len(file_list))\n",
        "# Find the first image in the list\n",
        "image_path = None\n",
        "for filename in file_list:\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        break\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Get the size of the image\n",
        "width, height = image.size\n",
        "image_input_size = (width,height)\n",
        "print(f\"Image size: {width} x {height}\")\n",
        "\n",
        "\n",
        "\n",
        "#image_dir = 'drive/MyDrive/68300/MLEKG/figures/'\n",
        "\n",
        "print(image_input_size)\n",
        "\n",
        "Y = pd.read_csv(labels_csv, index_col='ecg_id')\n",
        "matches = os.listdir(image_dir)\n",
        "matches = [int(f.rstrip(image_name_suffix)) for f in matches]\n",
        "#matches = [21817]\n",
        "\n",
        "#Remove all rows from Y unless ecg_id is in matches:\n",
        "Y = Y[Y.index.isin(matches)]\n",
        "\n",
        "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "# Load scp_statements.csv for diagnostic aggregation\n",
        "agg_df = pd.read_csv(scp_statements_csv, index_col=0)\n",
        "agg_df = agg_df[agg_df.diagnostic == 1]\n",
        "\n",
        "def aggregate_diagnostic(y_dic):\n",
        "    tmp = []\n",
        "    for key in y_dic.keys():\n",
        "        if key in agg_df.index:\n",
        "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
        "    return list(set(tmp))\n",
        "\n",
        "# Apply diagnostic superclass\n",
        "Y['diagnostic_individual_list'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
        "\n",
        "def compare_to_target_list(diagnostic_dict):\n",
        "    #target_list = ['WPW','2AVB']\n",
        "    target_list = [\n",
        "        'NDT', 'NST_', 'DIG', 'LNGQT', 'NORM', 'IMI', 'ASMI', 'LVH', 'LAFB', 'ISC_', 'IRBBB', '1AVB', 'IVCD', 'ISCAL', 'CRBBB',\n",
        "        'CLBBB', 'ILMI', 'LAO/LAE', 'AMI', 'ALMI', 'ISCIN', 'INJAS', 'LMI', 'ISCIL', 'LPFB', 'ISCAS', 'INJAL', 'ISCLA', 'RVH',\n",
        "        'ANEUR', 'RAO/RAE', 'EL', 'WPW', 'ILBBB', 'IPLMI', 'MI', 'STTC', 'HYP', 'ISCAN', 'IPMI', 'SEHYP', 'INJIN', 'INJLA',\n",
        "        'PMI', '3AVB', 'CD', 'INJIL', '2AVB','TRIGU',\n",
        "    ]\n",
        "    return_list = [diag for diag in diagnostic_dict.keys() if diag in target_list]\n",
        "    if len(return_list)<1:\n",
        "      #print(diagnostic_list)\n",
        "      return \"OTHER\"\n",
        "    if 'TRIGU' in return_list:\n",
        "      print(\"RETURNING TRIGU!\")\n",
        "      return 'TRIGU'\n",
        "    return return_list[0]\n",
        "\n",
        "\n",
        "\n",
        "print(Y['diagnostic_individual_list'])\n",
        "# apply function to the dataframe\n",
        "#Y['diagnostic_superclass'] = Y['diagnostic_individual_list'].apply(map_to_class)\n",
        "Y['diagnostic_superclass'] = Y['scp_codes'].apply(compare_to_target_list)\n",
        "\n",
        "print(Y['diagnostic_superclass'])\n",
        "# for index, row in Y.iterrows():\n",
        "#     print(f\"Row {index} --> diagnostic_individual_list: {row['diagnostic_individual_list']}, diagnostic_superclass: {row['diagnostic_superclass']}\")\n",
        "\n",
        "\n",
        "#classes_to_include = ['NORM', 'STTC']\n",
        "# # Filter the rows\n",
        "\n",
        "Y = Y[Y['diagnostic_superclass'].isin(classes_to_include)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Transform 'diagnostic_superclass' labels into numerical labels\n",
        "le = LabelEncoder()\n",
        "Y['diagnostic_superclass_num'] = le.fit_transform(Y['diagnostic_superclass'])\n",
        "\n",
        "\n",
        "# Assume that Y['diagnostic_superclass_num'] contains the numerical labels\n",
        "original_labels = le.inverse_transform(Y['diagnostic_superclass_num'].values)\n",
        "\n",
        "\n",
        "#print(original_labels)\n",
        "test_fold = [10]\n",
        "val_fold = [9]\n",
        "\n",
        "#y_numerical = Y.diagnostic_superclass.factorize()\n",
        "\n",
        "unique_labels, label_counts = np.unique(Y.diagnostic_superclass, return_counts=True)\n",
        "\n",
        "# Print the count of each unique label\n",
        "total_labels = 0\n",
        "for label, count in zip(unique_labels, label_counts):\n",
        "    print(f\"Label {label} appears {count} times\")\n",
        "    total_labels = total_labels + count\n",
        "\n",
        "print(f\"All Labels appears {total_labels} times\")\n",
        "\n",
        "\n",
        "y_val = Y[(Y.strat_fold.isin(val_fold))].diagnostic_superclass_num\n",
        "y_test = Y[Y.strat_fold.isin(test_fold)].diagnostic_superclass_num\n",
        "y_train = Y[(~Y.strat_fold.isin(val_fold)) & (~Y.strat_fold.isin(test_fold))].diagnostic_superclass_num\n",
        "\n",
        "\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(1234)\n",
        "  \n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU!\")\n",
        "else:\n",
        "    print(\"WARNING: Could not find GPU! Using CPU only\")\n",
        "    print(\"You may want to try to use the GPU in Google Colab by clicking in:\")\n",
        "    print(\"Runtime > Change Runtime type > Hardware accelerator > GPU.\")\n",
        "    \n",
        "    \n",
        "def initialize_model(model_name, num_classes, resume_from = None, use_pretrained = False):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    # The model (nn.Module) to return\n",
        "    model_ft = None\n",
        "    # The input image is expected to be (input_size, input_size)\n",
        "    #input_size = 0\n",
        "    \n",
        "    # By default, all parameters will be trained (useful when you're starting from scratch)\n",
        "    # Within this function you can set .requires_grad = False for various parameters, if you\n",
        "    # don't want to learn them\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = image_input_size\n",
        "        \n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = image_input_size\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = image_input_size\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Invalid model name!\")\n",
        "    \n",
        "    if resume_from is not None:\n",
        "        print(\"Loading weights from %s\" % resume_from)\n",
        "        model_ft.load_state_dict(torch.load(resume_from))\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "def make_optimizer(model, learning_rate, print_parameters=False):\n",
        "    # Get all the parameters\n",
        "    params_to_update = model.parameters()\n",
        "    if print_parameters:\n",
        "      print(\"Params to learn:\")\n",
        "      for name, param in model.named_parameters():\n",
        "          if param.requires_grad == True:\n",
        "              print(\"\\t\",name)\n",
        "\n",
        " \n",
        "    #optimizer = optim.SGD(params_to_update, lr=learning_rate, momentum=0.9)\n",
        "    optimizer = optim.Adam(params_to_update, lr=learning_rate)\n",
        "    #optimizer = optim.Adagrad(params_to_update, lr=learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "def get_loss():\n",
        "    # Create an instance of the loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    return criterion\n",
        "\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, save_dir = None, save_all_epochs=False, num_epochs=25):\n",
        "    '''\n",
        "    model: The NN to train\n",
        "    dataloaders: A dictionary containing at least the keys \n",
        "                 'train','val' that maps to Pytorch data loaders for the dataset\n",
        "    criterion: The Loss function\n",
        "    optimizer: The algorithm to update weights \n",
        "               (Variations on gradient descent)\n",
        "    num_epochs: How many epochs to train for\n",
        "    save_dir: Where to save the best model weights that are found, \n",
        "              as they are found. Will save to save_dir/weights_best.pt\n",
        "              Using None will not write anything to disk\n",
        "    save_all_epochs: Whether to save weights for ALL epochs, not just the best\n",
        "                     validation error epoch. Will save to save_dir/weights_e{#}.pt\n",
        "    '''\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    train_acc_history = []\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                print(\"switching model to train\")\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            # TQDM has nice progress bars\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backprop + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            \n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "            if save_all_epochs:\n",
        "                torch.save(model.state_dict(), os.path.join(save_dir, f'weights_{epoch}.pt'))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # save and load best model weights\n",
        "    torch.save(best_model_wts, os.path.join(save_dir, 'weights_best_val_acc.pt'))\n",
        "    torch.save(model.state_dict(), os.path.join(save_dir, 'weights_last.pt'.format(epoch)))\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, train_acc_history\n",
        "\n",
        "def get_image_transforms():\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    return transform\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, image_ids, labels, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.image_ids = image_ids\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.data_dir, f\"{str(self.image_ids[idx]).zfill(5)}{image_name_suffix}\")\n",
        "        image = Image.open(img_name)\n",
        "        \n",
        "        # Check if the image has a corresponding label\n",
        "        if self.labels is not None:\n",
        "            label = self.labels[idx]\n",
        "        else:\n",
        "            label = None\n",
        "        \n",
        "        # Apply data augmentation if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "def make_balanced_sampler(labels):\n",
        "    class_counts = np.bincount(labels)\n",
        "    class_weights = 1. / class_counts\n",
        "    samples_weights = class_weights[labels]\n",
        "    sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)\n",
        "    return sampler\n",
        "\n",
        "\n",
        "def get_dataloaders(dataset_dir, input_size, batch_size, shuffle=True, transform=get_image_transforms()):\n",
        "    data_transforms = {\n",
        "        'train': transform,\n",
        "        'val': transform,\n",
        "        'test': transform\n",
        "    }\n",
        "\n",
        "    # Get the list of image IDs with labels\n",
        "    train_image_ids = y_train.index[y_train.notnull()]\n",
        "    val_image_ids = y_val.index[y_val.notnull()]\n",
        "    test_image_ids = y_test.index[y_test.notnull()]\n",
        "\n",
        "    # Get the labels for the images with labels\n",
        "    train_labels = y_train.loc[train_image_ids].to_numpy()\n",
        "    val_labels = y_val.loc[val_image_ids].to_numpy()\n",
        "    test_labels = y_test.loc[test_image_ids].to_numpy()\n",
        "    \n",
        "    # Make a balanced sampler for the training set\n",
        "    train_sampler = make_balanced_sampler(train_labels)\n",
        "\n",
        "    # Create the datasets\n",
        "    train_dataset = CustomDataset(dataset_dir, train_image_ids, train_labels, transform=data_transforms['train'])\n",
        "    val_dataset = CustomDataset(dataset_dir, val_image_ids, val_labels, transform=data_transforms['val'])\n",
        "    test_dataset = CustomDataset(dataset_dir, test_image_ids, test_labels, transform=data_transforms['test'])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
        "\n",
        "    dataloaders_dict = {\n",
        "        'train': train_dataloader,\n",
        "        'val': val_dataloader,\n",
        "        'test': test_dataloader\n",
        "    }\n",
        "    return dataloaders_dict\n",
        "\n",
        "\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
        "# You can add your own, or modify these however you wish!\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = Y['diagnostic_superclass'].nunique()\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "\n",
        "# Shuffle the input data?\n",
        "shuffle_datasets = True\n",
        "\n",
        "# Number of epochs to train for \n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "### IO\n",
        "# Path to a model file to use to start weights at\n",
        "resume_from = None\n",
        "\n",
        "# Whether to use a pretrained model, trained for classification in Imagenet-1k \n",
        "pretrained = False\n",
        "\n",
        "# Save all epochs so that you can select the model from a particular epoch\n",
        "save_all_epochs = False\n",
        "\n",
        "# Whether to use early stopping (load the model with best accuracy), or not\n",
        "early_stopping = True\n",
        "\n",
        "# Directory to save weights to\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Initialize the model for this run\n",
        "# train model_1\n",
        "model_1, input_size = initialize_model(model_name = model_name, num_classes = num_classes, resume_from=resume_from, use_pretrained=pretrained)\n",
        "dataloaders = get_dataloaders(image_dir, input_size, batch_size, shuffle_datasets)\n",
        "criterion = get_loss()\n",
        "\n",
        "\n",
        "train_dataloader = dataloaders['train']\n",
        "\n",
        "num_batches_to_print = 3\n",
        "\n",
        "if train_the_model:\n",
        "  # Move the model to the gpu if needed\n",
        "  model_1 = model_1.to(device)\n",
        "\n",
        "  optimizer_1 = make_optimizer(model_1, learning_rate)\n",
        "\n",
        "  # Train the model!\n",
        "  trained_model_1, validation_history_1, train_history_1 = train_model(model=model_1, \n",
        "                                                                      dataloaders=dataloaders, \n",
        "                                                                      criterion=criterion, \n",
        "                                                                      optimizer=optimizer_1,\n",
        "                                                                      save_dir=save_dir, \n",
        "                                                                      save_all_epochs=save_all_epochs, \n",
        "                                                                      num_epochs=num_epochs)\n",
        "  del model_1, optimizer_1, trained_model_1\n"
      ],
      "metadata": {
        "id": "cUGtK7fhaWWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}